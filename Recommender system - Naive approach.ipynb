{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import numpy_indexed as npi\n",
    "from scipy  import sparse\n",
    "from scipy.sparse import lil_matrix\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "ratings=[]\n",
    "f = open(\"dataset/ratings.dat\", 'r')\n",
    "for line in f:\n",
    "    data = line.split('::')\n",
    "    ratings.append([int(z) for z in data])\n",
    "f.close()\n",
    "ratings = np.array(ratings)\n",
    "allUserId = set(range(1,np.max(ratings[:,0])+1))\n",
    "allItemId = set(range(1,np.max(ratings[:,1])+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into 5 train and test folds\n",
    "nfolds=5\n",
    "\n",
    "#to make sure you are able to repeat results, set the random seed to something:\n",
    "np.random.seed(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allocate memory for results:\n",
    "rmseTrainRatings=np.zeros(nfolds)\n",
    "rmseTestRatings=np.zeros(nfolds)\n",
    "rmseTrainUsers=np.zeros(nfolds)\n",
    "rmseTestUsers=np.zeros(nfolds)\n",
    "rmseTrainItems=np.zeros(nfolds)\n",
    "rmseTestItems=np.zeros(nfolds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "maeTrainRatings=np.zeros(nfolds)\n",
    "maeTestRatings=np.zeros(nfolds)\n",
    "maeTrainUsers=np.zeros(nfolds)\n",
    "maeTestUsers=np.zeros(nfolds)\n",
    "maeTrainItems=np.zeros(nfolds)\n",
    "maeTestItems=np.zeros(nfolds)\n",
    "\n",
    "rmseLinear=np.zeros(nfolds)\n",
    "maeLinear=np.zeros(nfolds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c4356bc1134a54883dea274901a1c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:51: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Cross validation\n",
    "seqs=[x%nfolds for x in range(len(ratings))]\n",
    "np.random.shuffle(seqs)\n",
    "#for each fold:\n",
    "for fold in tqdm(range(nfolds)):\n",
    "    train_sel=np.array([x!=fold for x in seqs])\n",
    "    test_sel=np.array([x==fold for x in seqs])\n",
    "    train=ratings[train_sel]\n",
    "    test=ratings[test_sel]\n",
    "    \n",
    "    #calculate model parameters: mean rating over the training set:\n",
    "    gmr=np.mean(train[:,2])\n",
    "\n",
    "    #apply the model to the train set:\n",
    "    rmseTrainRatings[fold]=np.sqrt(np.mean((train[:,2]-gmr)**2))\n",
    "    maeTrainRatings[fold]=np.mean(np.fabs(train[:,2]-gmr))\n",
    "\n",
    "    #apply the model to the test set:\n",
    "    rmseTestRatings[fold]=np.sqrt(np.mean((test[:,2]-gmr)**2))\n",
    "    maeTestRatings[fold]=np.mean(np.fabs(test[:,2]-gmr))\n",
    "    #doing the same for user and item average\n",
    "    meanUser = npi.group_by(train[:,0]).mean(train[:,2])\n",
    "    meanUser = (meanUser[0].tolist(),meanUser[1].tolist())\n",
    "\n",
    "    meanItem = npi.group_by(train[:,1]).mean(train[:,2])\n",
    "    meanItem = (meanItem[0].tolist(),meanItem[1].tolist())\n",
    "\n",
    "    #finding the missing element in the training set and apply fall-back\n",
    "    for i in list(set(meanUser[0]) ^ allUserId):\n",
    "        meanUser[1].insert(i-1,gmr)\n",
    "    meanUser = meanUser[1]\n",
    "    for i in list(set(meanItem[0]) ^ allItemId):\n",
    "        meanItem[1].insert(i-1,gmr)\n",
    "    meanItem = meanItem[1]\n",
    "\n",
    "    #Create a list of means of user/item for each user/item in the data set\n",
    "    #These can be used to calculate the rmse, mae and apply as R_user and R_item in linear regression\n",
    "    replicatedUserRatings = [meanUser[e-1] for e in train[:,0]]\n",
    "    replicatedItemRatings = [meanItem[e-1] for e in train[:,1]]\n",
    "\n",
    "    #calculate mae and rmse\n",
    "    maeTrainUsers[fold] = np.mean(np.fabs(train[:,2]-replicatedUserRatings))\n",
    "    maeTrainItems[fold] = np.mean(np.fabs(train[:,2]-replicatedItemRatings))\n",
    "    rmseTrainUsers[fold] = np.sqrt(np.mean((train[:,2]-replicatedUserRatings)**2))\n",
    "    rmseTrainItems[fold] = np.sqrt(np.mean((train[:,2]-replicatedItemRatings)**2))\n",
    "\n",
    "    #use vstack to concanate R_user,R_item and 1:s vector to create input for the linear regression\n",
    "    inputLstsq = np.vstack((replicatedUserRatings,replicatedItemRatings))\n",
    "    inputLstsq = np.vstack((inputLstsq,np.ones(len(replicatedUserRatings)))).T\n",
    "    #applu to np.linalg.lstsq to get the A,B and C constant\n",
    "    a,b,c = np.linalg.lstsq(inputLstsq,train[:,2])[0]\n",
    "\n",
    "    #Create a list of means of user/item for each user/item in the data set\n",
    "    replicatedUserRatings = [meanUser[e-1] for e in test[:,0]]\n",
    "    replicatedItemRatings = [meanItem[e-1] for e in test[:,1]]\n",
    "    #calculate mae and rmse\n",
    "    maeTestUsers[fold] = np.mean(np.fabs(test[:,2]-replicatedUserRatings))\n",
    "    maeTestItems[fold] = np.mean(np.fabs(test[:,2]-replicatedItemRatings))\n",
    "    rmseTestUsers[fold] = np.sqrt(np.mean((test[:,2]-replicatedUserRatings)**2))\n",
    "    rmseTestItems[fold] = np.sqrt(np.mean((test[:,2]-replicatedItemRatings)**2))\n",
    "\n",
    "    #use vstack to concanate R_user, R_item to test the accuracy of linear regression\n",
    "    inputLstsq = np.vstack((replicatedUserRatings,replicatedItemRatings)).T\n",
    "    #print([math.fabs(row[0]*a + row[1]*b + c - row[2]) for row in test[:,[0,1,2]]])\n",
    "    predictions = [(inputLstsq[i][0]*a + inputLstsq[i][1]*b + c) for i in range(len(inputLstsq))]\n",
    "    for prediction in predictions:\n",
    "        if prediction > 5:\n",
    "            prediction = 5\n",
    "        elif prediction < 1:\n",
    "            prediction = 1\n",
    "    #calculate the rmse and mae on the test set\n",
    "    rmseLinear[fold] = np.sqrt(np.mean((predictions - test[:,2])**2))\n",
    "    maeLinear[fold] = np.mean(np.fabs(predictions - test[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "rmse global on TRAIN:  [1.11731523 1.11701016 1.11699529 1.11745511 1.11672984]\n",
      "rmse global on TEST:  [1.11624744 1.11746575 1.11752522 1.11568491 1.11858662]\n",
      "rmse users on TRAIN:  [1.02785404 1.02778599 1.02773065 1.02781842 1.02717027]\n",
      "rmse users on TEST:  [1.03473763 1.03500099 1.03527038 1.03492534 1.03752907]\n",
      "rmse items on TRAIN:  [0.9744298  0.97409031 0.97433361 0.97460831 0.97362513]\n",
      "rmse items on TEST:  [0.97849937 0.98006458 0.97906966 0.97780916 0.98185046]\n",
      "rmse LINEAR on TEST:  [0.92285057 0.92513506 0.92361311 0.92349392 0.92694415]\n",
      "mea global on TRAIN:  [0.93396319 0.93394206 0.9337667  0.93419246 0.93343936]\n",
      "mea global on TEST:  [0.93422056 0.93343997 0.93411512 0.93242426 0.93510661]\n",
      "mea users on TRAIN:  [0.82238788 0.82291956 0.82296344 0.82302252 0.82239199]\n",
      "mea users on TEST:  [0.8293142  0.82831617 0.82887167 0.82776207 0.83057375]\n",
      "mea items on TRAIN:  [0.77824597 0.77836482 0.77824482 0.77893227 0.77790328]\n",
      "mea items on TEST:  [0.78209687 0.78219076 0.78270683 0.78082438 0.78420163]\n",
      "mea LINEAR on TEST:  [0.7320158  0.7329174  0.73227772 0.73169071 0.734877  ]\n"
     ]
    }
   ],
   "source": [
    "#print the final conclusion:\n",
    "print(\"\\n\")\n",
    "print(\"rmse global on TRAIN: \", rmseTrainRatings)\n",
    "print(\"rmse global on TEST: \", rmseTestRatings)\n",
    "print(\"rmse users on TRAIN: \", rmseTrainUsers)\n",
    "print(\"rmse users on TEST: \", rmseTestUsers)\n",
    "print(\"rmse items on TRAIN: \", rmseTrainItems)\n",
    "print(\"rmse items on TEST: \", rmseTestItems)\n",
    "print(\"rmse LINEAR on TEST: \", rmseLinear)\n",
    "\n",
    "print(\"mea global on TRAIN: \", maeTrainRatings)\n",
    "print(\"mea global on TEST: \", maeTestRatings)\n",
    "print(\"mea users on TRAIN: \", maeTrainUsers)\n",
    "print(\"mea users on TEST: \", maeTestUsers)\n",
    "print(\"mea items on TRAIN: \", maeTrainItems)\n",
    "print(\"mea items on TEST: \", maeTestItems)\n",
    "print(\"mea LINEAR on TEST: \", maeLinear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
